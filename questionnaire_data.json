{
  "pillars": {
    "Strategy & Value": [
      {
        "pillar": "Strategy & Value",
        "indicator": "AI strategy linked to OKRs",
        "scoring": "1 to 5",
        "question": "Leadership has a clear grasp of both the opportunities and constraints presented by AI adoption."
      },
      {
        "pillar": "Strategy & Value",
        "indicator": "Use-case portfolio & prioritization",
        "scoring": "1 to 5",
        "question": "We have indentified the business use cases for AI in our company that best fit with our business objectives"
      },
      {
        "pillar": "Strategy & Value",
        "indicator": "Use-case portfolio & prioritization",
        "scoring": "1 to 5",
        "question": "There has been prioritization of these use cases through brainstorming and workshop sessions based on objectives, business impact, and feasibility."
      },
      {
        "pillar": "Strategy & Value",
        "indicator": "Time-to-value process defined",
        "scoring": "1 to 5",
        "question": "There is an AI roadmap linking AI projects to measurable ROI outcomes."
      },
      {
        "pillar": "Strategy & Value",
        "indicator": "Value tracking & KPIs in place",
        "scoring": "1 to 5",
        "question": "The company has set clear KPIs or metrics to measure AI impact (cost, time, safety, quality)"
      },
      {
        "pillar": "Strategy & Value",
        "indicator": "AI strategy linked to OKRs",
        "scoring": "1 to 5",
        "question": "The AI projects are in line, and part of the organizational strategy not just siloed pilots."
      }
    ],
    "Governance, Ethics & Compliance": [
      {
        "pillar": "Governance, Ethics & Compliance",
        "indicator": "Data governance team",
        "scoring": "1 to 5",
        "question": "There is a data governance team with roles clearly defined."
      },
      {
        "pillar": "Governance, Ethics & Compliance",
        "indicator": "Policy & documentation (DPIA/RA)",
        "scoring": "1 to 5",
        "question": "The company has a data governance framework in place."
      },
      {
        "pillar": "Governance, Ethics & Compliance",
        "indicator": "Human-in-the-loop for high-risk",
        "scoring": "1 to 5",
        "question": "If the AI makes a recommendation that affects people, is there an assigned person responsible for reviewing and approving it?"
      }
    ],
    "Data Foundations": [
      {
        "pillar": "Data Foundations",
        "indicator": "Data catalog & ownership defined",
        "scoring": "1 to 5",
        "question": "Do we know which datasets/documents we will use for AI training and/or usage and who owns them?"
      },
      {
        "pillar": "Data Foundations",
        "indicator": "Data catalog & ownership defined",
        "scoring": "1 to 5",
        "question": "Proprietary and sensitive data are classified, with clear rules for AI usage."
      },
      {
        "pillar": "Data Foundations",
        "indicator": "Quality SLAs & monitoring",
        "scoring": "1 to 5",
        "question": "Are robust data quality management processes in place to ensure that data is consistently cleaned, structured, and kept up to date?"
      }
    ],
    "People, Skills & Culture": [
      {
        "pillar": "People, Skills & Culture",
        "indicator": "AI Company Culture",
        "scoring": "1 to 5",
        "question": "Leadership has communicated a vision for AI use and there is a company-wide understanding of its importance to the business."
      },
      {
        "pillar": "People, Skills & Culture",
        "indicator": "Cross-functional delivery teams",
        "scoring": "1 to 5",
        "question": "Are there frequent cross department meetings about the application of AI in the company?"
      },
      {
        "pillar": "People, Skills & Culture",
        "indicator": "Role coverage (product/data/ML/risk)",
        "scoring": "1 to 5",
        "question": "Have key roles for AI implementation been formally designated: including a product owner, data/ML engineer, and risk or compliance officer?"
      }
    ],
    "Data, Platforms & MLOps": [
      {
        "pillar": "Data, Platforms & MLOps",
        "indicator": "Interoperability & APIs",
        "scoring": "1 to 5",
        "question": "Is there a clear integration pathway to connect the AI model with the product that will use it (e.g., through an API or file exchange)?"
      },
      {
        "pillar": "Data, Platforms & MLOps",
        "indicator": "Reproducible pipelines & versioning",
        "scoring": "1 to 5",
        "question": "Is the AI pipeline, the environments and dependencies documented and version-controlled to ensure full reproducibility by other users?"
      },
      {
        "pillar": "Data, Platforms & MLOps",
        "indicator": "Monitoring (drift/quality/incidents)",
        "scoring": "1 to 5",
        "question": "Are there methods in place to verify both the AI's predictive accuracy and its immediate impact on business outcomes?"
      },
      {
        "pillar": "Data, Platforms & MLOps",
        "indicator": "Training & enablement programs",
        "scoring": "1 to 5",
        "question": "Does the team responsible for MLOps have a clear understanding of the existing systems, tools, and workflows relevant to the AI project?"
      }
    ],
    "Process & Stakeholders": [
      {
        "pillar": "Process & Stakeholders",
        "indicator": "Adoption & change mgmt",
        "scoring": "1 to 5",
        "question": "Do you know your primary user group of the AI tool and have prepared the needed training/support?"
      },
      {
        "pillar": "Process & Stakeholders",
        "indicator": "Usage/sentiment measurement",
        "scoring": "1 to 5",
        "question": "There is a defined process (e.g., short surveys, check-ins, user activity) to gather early user feedback for early implementation."
      },
      {
        "pillar": "Process & Stakeholders",
        "indicator": "Stakeholder reviews in lifecycle",
        "scoring": "1 to 5",
        "question": "Have at least three end users of the AI tool been consulted to collaboratively define the success criteria for the AI?"
      }
    ],
    "EU AI Act Compliance": [
      {
        "pillar": "EU AI Act Compliance",
        "indicator": "Prohibited Practices (Fatal Risk)",
        "scoring": "Yes/No",
        "question": "Does the AI tool you are implementing utilize psychological manipulation or similar techniques to exploit user vulnerabilities?\n\nExamples: An AI in a mobile app's UI promoting harmful addiction, a design tool subtly changing product information to pressure a vulnerable customer into an immediate purchase, or a worker management tool exploiting employee stress to coerce acceptance of unfavorable work hours?"
      },
      {
        "pillar": "EU AI Act Compliance",
        "indicator": "Prohibited Practices (Fatal Risk)",
        "scoring": "Yes/No",
        "question": "Does the AI tool you are implementing perform real-time facial or biometric identification of people in operational settings?\n\nExamples: Live facial recognition of customers in a smart store, tracking workers with camera systems on a factory floor, or using real-time biometrics in public installations for non-consensual profiling?"
      },
      {
        "pillar": "EU AI Act Compliance",
        "indicator": "Prohibited Practices (Fatal Risk)",
        "scoring": "Yes/No",
        "question": "Does the AI tool employ any technique that could result in unfair discrimination in HR processes (hiring, performance) or in product recommendation algorithms?"
      },
      {
        "pillar": "EU AI Act Compliance",
        "indicator": "Prohibited Practices (Fatal Risk)",
        "scoring": "Yes/No",
        "question": "Does your AI system process biometric data (e.g., fingerprints, voice patterns, gaze tracking) to infer and categorize sensitive employee or user traits such as emotional state, political opinions, or health risk in products, design testing, or personnel monitoring?"
      },
      {
        "pillar": "EU AI Act Compliance",
        "indicator": "Prohibited Practices (Fatal Risk)",
        "scoring": "Yes/No",
        "question": "Does the AI system build or expand a facial recognition database using imagery gathered in an untargeted or non-consensual manner, such as scraping social media data, indexing images in a public design archive, or automatically collecting video of workers beyond access control?"
      },
      {
        "pillar": "EU AI Act Compliance",
        "indicator": "Prohibited Practices (Fatal Risk)",
        "scoring": "Yes/No",
        "question": "Is the system used by security or HR to predict misconduct or criminal behavior of employees or contractors on premises?"
      },
      {
        "pillar": "EU AI Act Compliance",
        "indicator": "High-Risk Practices (Mandatory Compliance)",
        "scoring": "Yes/No",
        "question": "Is the AI system designed to directly manage or control safety-critical operations within infrastructure, such as automated factory floor processes, core supply chain logistics and routing, or real-time energy distribution or utility control systems?"
      },
      {
        "pillar": "EU AI Act Compliance",
        "indicator": "High-Risk Practices (Mandatory Compliance)",
        "scoring": "Yes/No",
        "question": "The system utilized in job candidate screening, employee performance scoring, and prioritizing individuals for promotion or termination within organizations often involves a combination of structured assessment methods.  Is the system utilized in job candidate screening, employee performance scoring, or prioritizing individuals for promotion/termination within your organization?"
      },
      {
        "pillar": "EU AI Act Compliance",
        "indicator": "High-Risk Practices (Mandatory Compliance)",
        "scoring": "Yes/No",
        "question": "Does the system not govern access to essential or public sector services alone? Or does it operate with human oversight and intervention, ensuring that decisions are transparent, accountable, and aligned with ethical and societal values? By integrating human expertise, feedback, and review mechanisms, does the platform balance automation with fairness, adaptability, and inclusivity?"
      },
      {
        "pillar": "EU AI Act Compliance",
        "indicator": "High-Risk Practices (Mandatory Compliance)",
        "scoring": "Yes/No",
        "question": "Does the system serve as a decision-support tool, providing data-driven insights to human professionals who retain full authority and responsibility for final judgments?"
      },
      {
        "pillar": "EU AI Act Compliance",
        "indicator": "High-Risk Practices (Mandatory Compliance)",
        "scoring": "Yes/No",
        "question": "Is the AI system integrated as a safety component into a physical product, such as an industrial robot or machine, a vehicle control system, or a lift/elevator that is already subject to mandatory third-party safety certification under specific EU product law?"
      },
      {
        "pillar": "EU AI Act Compliance",
        "indicator": "High-Risk Practices (Mandatory Compliance)",
        "scoring": "Yes/No",
        "question": "Does the system make independent decisions in law enforcement, border control, or migration processes? Or does it serve as a decision-support tool, providing data-driven insights to human professionals who retain full authority and responsibility for final judgments? By integrating human expertise, ethical guidelines, and legal frameworks, do we ensure that decisions are transparent, accountable, and aligned with fundamental rights and societal values?"
      },
      {
        "pillar": "EU AI Act Compliance",
        "indicator": "High-Risk Practices (Mandatory Compliance)",
        "scoring": "Yes/No",
        "question": "Is the AI system used for real-time risk assessment or allocation of urgent interventions, such as predicting the critical failure of factory machinery, or prioritizing cybersecurity incident response in a tech service, or determining emergency infrastructure resource allocation in a smart city solution?"
      },
      {
        "pillar": "EU AI Act Compliance",
        "indicator": "High-Risk Practices (Mandatory Compliance)",
        "scoring": "Yes/No",
        "question": "Does the AI system have the potential to cause significant injury, death, or severe property damage if it fails or operates incorrectly, such as robotics control systems on a factory floor, an automated vehicle component, or faulty structural design analysis software?"
      },
      {
        "pillar": "EU AI Act Compliance",
        "indicator": "Minimal/Low-Risk Practices (Transparency Obligations)",
        "scoring": "Yes/No",
        "question": "Are users of your software or product always informed when they are interacting with an AI (e.g., a chatbot or design assistant)?"
      },
      {
        "pillar": "EU AI Act Compliance",
        "indicator": "Minimal/Low-Risk Practices (Transparency Obligations)",
        "scoring": "Yes/No",
        "question": "When your system generates synthetic media (deepfakes, altered images/audio), is the artificial origin clearly labeled and disclosed to the recipient?"
      },
      {
        "pillar": "EU AI Act Compliance",
        "indicator": "Minimal/Low-Risk Practices (Transparency Obligations)",
        "scoring": "Yes/No",
        "question": "When the system generates or manipulates text for public release (e.g., product descriptions, reports), is it clearly identified that the content is machine-generated?"
      },
      {
        "pillar": "EU AI Act Compliance",
        "indicator": "Minimal/Low-Risk Practices (Transparency Obligations)",
        "scoring": "Yes/No",
        "question": "If your system directly interacts with people (e.g., an automated customer service tool), is it evident to the person that the output is from an AI?"
      },
      {
        "pillar": "EU AI Act Compliance",
        "indicator": "Minimal/Low-Risk Practices (Transparency Obligations)",
        "scoring": "Yes/No",
        "question": "Has the AI been reviewed to ensure its recommendations or personalized content do not negatively influence a user's autonomy or well-being (e.g., manipulative advertising)?"
      }
    ]
  },
  "total_questions": 41
}
