// Auto-generated from AI_Readiness_Checklist.xlsx
import { Question } from "@/types/questionnaire";

export const QUESTIONS: Question[] = [
  {
    "id": 1,
    "pillar": "Strategy & Value",
    "indicator": "AI strategy linked to OKRs",
    "scoring": "1 to 5",
    "question": "Leadership understands AI's potentials and limitations"
  },
  {
    "id": 2,
    "pillar": "Strategy & Value",
    "indicator": "AI strategy linked to OKRs",
    "scoring": "1 to 5",
    "question": "Are the AI projects in line, and part of the organizational strategy not just siloed pilots."
  },
  {
    "id": 3,
    "pillar": "Strategy & Value",
    "indicator": "Use-case portfolio & prioritization",
    "scoring": "1 to 5",
    "question": "We have indentified the business use cases for AI in our company that best fit with our business objectives"
  },
  {
    "id": 4,
    "pillar": "Strategy & Value",
    "indicator": "Use-case portfolio & prioritization",
    "scoring": "1 to 5",
    "question": "There has been prioritization of these use cases through brainstorming and workshop sessions based on objectives, business impact, and feasibility"
  },
  {
    "id": 5,
    "pillar": "Strategy & Value",
    "indicator": "Value tracking & KPIs in place",
    "scoring": "1 to 5",
    "question": "The company has set clear KPIs or metrics to measure AI impact (cost, time, safety, quality)"
  },
  {
    "id": 6,
    "pillar": "Strategy & Value",
    "indicator": "Time-to-value process defined",
    "scoring": "1 to 5",
    "question": "There is an AI roadmap linking AI projects to measurable ROI outcomes."
  },
  {
    "id": 7,
    "pillar": "Governance, Ethics & Compliance",
    "indicator": "Human-in-the-loop for high-risk",
    "scoring": "1 to 5",
    "question": "If this affects people, who reviews/overrides the decision and is it in the workflow?"
  },
  {
    "id": 8,
    "pillar": "Governance, Ethics & Compliance",
    "indicator": "Policy & documentation (DPIA/RA)",
    "scoring": "1 to 5",
    "question": "Is there a data governance framework in place?"
  },
  {
    "id": 9,
    "pillar": "Governance, Ethics & Compliance",
    "indicator": "Data governance team",
    "scoring": "1 to 5",
    "question": "There is a data governance team with roles clearly defined."
  },
  {
    "id": 10,
    "pillar": "Data Foundations",
    "indicator": "Data catalog & ownership defined",
    "scoring": "1 to 5",
    "question": "Do we know which datasets/documents we will use and who owns them?"
  },
  {
    "id": 11,
    "pillar": "Data Foundations",
    "indicator": "Data catalog & ownership defined",
    "scoring": "1 to 5",
    "question": "Proprietary and sensitive data are classified, with clear rules for AI usage."
  },
  {
    "id": 12,
    "pillar": "Data Foundations",
    "indicator": "Quality SLAs & monitoring",
    "scoring": "1 to 5",
    "question": "Are data quality management processes established and effectively implemented?"
  },
  {
    "id": 13,
    "pillar": "Data Foundations",
    "indicator": "RAG-ready content/corpus (if relevant)",
    "scoring": "1 to 5",
    "question": "Data is cleaned, structured, and up to date."
  },
  {
    "id": 14,
    "pillar": "People, Skills & Culture",
    "indicator": "Role coverage (product/data/ML/risk)",
    "scoring": "1 to 5",
    "question": "Have key roles for AI implementation been formally designated: including a product owner, data/ML engineer, and risk or compliance officer?"
  },
  {
    "id": 15,
    "pillar": "People, Skills & Culture",
    "indicator": "Training & enablement programs",
    "scoring": "1 to 5",
    "question": "Does the team have a clear understanding of the existing systems, tools, and workflows relevant to the AI project?"
  },
  {
    "id": 16,
    "pillar": "People, Skills & Culture",
    "indicator": "Adoption & change mgmt",
    "scoring": "1 to 5",
    "question": "Are the primary user groups defined, and is a support or training plan in place to ensure effective use?"
  },
  {
    "id": 17,
    "pillar": "People, Skills & Culture",
    "indicator": "Usage/sentiment measurement",
    "scoring": "1 to 5",
    "question": "Is there a system in place to monitor user activity and collect timely feedback during early implementation?"
  },
  {
    "id": 18,
    "pillar": "People, Skills & Culture",
    "indicator": "AI Company Culture",
    "scoring": "1 to 5",
    "question": "Leadership has communicated a vision for AI use and there is a company-wide understanding of its importance to the business."
  },
  {
    "id": 19,
    "pillar": "People, Skills & Culture",
    "indicator": "Cross-functional delivery teams",
    "scoring": "1 to 5",
    "question": "Are there frequent cross department meetings?"
  },
  {
    "id": 20,
    "pillar": "Data, Platforms & MLOps",
    "indicator": "Interoperability & APIs",
    "scoring": "1 to 5",
    "question": "Is there a clear integration pathway to connect the AI model with the product that will use it (e.g., through an API or file exchange)?"
  },
  {
    "id": 21,
    "pillar": "Data, Platforms & MLOps",
    "indicator": "Reproducible pipelines & versioning",
    "scoring": "1 to 5",
    "question": "Is the AI pipeline, the environments and dependencies documented and version-controlled to ensure full reproducibility by other users?"
  },
  {
    "id": 22,
    "pillar": "Data, Platforms & MLOps",
    "indicator": "Monitoring (drift/quality/incidents)",
    "scoring": "1 to 5",
    "question": "Are there systems in place to verify both the AI's predictive accuracy and its immediate impact on business outcomes?"
  },
  {
    "id": 23,
    "pillar": "Process & Stakeholders",
    "indicator": "Customer/citizen engagement loops",
    "scoring": "1 to 5",
    "question": "Have we spoken to at least 3 end users and agreed success criteria?"
  },
  {
    "id": 24,
    "pillar": "Process & Stakeholders",
    "indicator": "Stakeholder reviews in lifecycle",
    "scoring": "1 to 5",
    "question": "Are end users involved in defining what success looks like for the AI, with at least three consulted so far?"
  },
  {
    "id": 25,
    "pillar": "EU AI Act Compliance",
    "indicator": "Prohibited Practices (Fatal Risk)",
    "scoring": "Yes/No",
    "question": "Does the AI system utilize psychological manipulation or similar techniques to exploit user vulnerabilities, such as an AI in a mobile app's UI promoting harmful addiction, a design tool subtly changing product information to pressure a vulnerable customer into an immediate purchase, or a worker management tool exploiting employee stress to coerce acceptance of unfavorable work hours?"
  },
  {
    "id": 26,
    "pillar": "EU AI Act Compliance",
    "indicator": "Prohibited Practices (Fatal Risk)",
    "scoring": "Yes/No",
    "question": "Is the AI system used to perform real-time facial or biometric identification of people in operational settings, such as live facial recognition of customers in a smart store, tracking workers with camera systems on a factory floor, or using real-time biometrics in public installations for non-consensual profiling?"
  },
  {
    "id": 27,
    "pillar": "EU AI Act Compliance",
    "indicator": "Prohibited Practices (Fatal Risk)",
    "scoring": "Yes/No",
    "question": "In HR, artificial intelligence hiring systems (AHSs) often rely on training data that reflects historical hiring patterns, which can encode existing biases.  For example, Amazon developed an AI recruiting tool trained on resumes submitted over a ten-year period, which were predominantly from men. As a result, the algorithm learned to downrank resumes containing words associated with women, such as \"women's\" or \"female,\" and even rejected applicants from all-women's colleges, effectively discriminating against qualified female candidates. Does the system employ any technique that could result in unfair discrimination in HR processes (hiring, performance) or in product recommendation algorithms?"
  },
  {
    "id": 28,
    "pillar": "EU AI Act Compliance",
    "indicator": "Prohibited Practices (Fatal Risk)",
    "scoring": "Yes/No",
    "question": "Does the AI system process biometric data (e.g., fingerprints, voice patterns, gaze tracking) to infer and categorize sensitive employee or user traits such as emotional state, political opinions, or health risk in products, design testing, or personnel monitoring?"
  },
  {
    "id": 29,
    "pillar": "EU AI Act Compliance",
    "indicator": "Prohibited Practices (Fatal Risk)",
    "scoring": "Yes/No",
    "question": "Does the AI system build or expand a facial recognition database using imagery gathered in an untargeted or non-consensual manner, such as scraping social media data, indexing images in a public design archive, or automatically collecting video of workers beyond access control?"
  },
  {
    "id": 30,
    "pillar": "EU AI Act Compliance",
    "indicator": "Prohibited Practices (Fatal Risk)",
    "scoring": "Yes/No",
    "question": "Is the system used by security or HR to predict misconduct or criminal behavior of employees or contractors on premises?"
  },
  {
    "id": 31,
    "pillar": "EU AI Act Compliance",
    "indicator": "High-Risk Practices (Mandatory Compliance)",
    "scoring": "Yes/No",
    "question": "Is the AI system designed to directly manage or control safety-critical operations within infrastructure, such as automated factory floor processes, core supply chain logistics and routing, or real-time energy distribution or utility control systems?"
  },
  {
    "id": 32,
    "pillar": "EU AI Act Compliance",
    "indicator": "High-Risk Practices (Mandatory Compliance)",
    "scoring": "Yes/No",
    "question": "The system utilized in job candidate screening, employee performance scoring, and prioritizing individuals for promotion or termination within organizations often involves a combination of structured assessment methods.  Is the system utilized in job candidate screening, employee performance scoring, or prioritizing individuals for promotion/termination within your organization?"
  },
  {
    "id": 33,
    "pillar": "EU AI Act Compliance",
    "indicator": "High-Risk Practices (Mandatory Compliance)",
    "scoring": "Yes/No",
    "question": "Does the system not govern access to essential or public sector services alone? Or does it operate with human oversight and intervention, ensuring that decisions are transparent, accountable, and aligned with ethical and societal values? By integrating human expertise, feedback, and review mechanisms, does the platform balance automation with fairness, adaptability, and inclusivity?"
  },
  {
    "id": 34,
    "pillar": "EU AI Act Compliance",
    "indicator": "High-Risk Practices (Mandatory Compliance)",
    "scoring": "Yes/No",
    "question": "Is the AI system applied to dispatch, control, or safety-critical functions where failure could lead to harm, such as in: automated vehicle control or traffic management, core production line robotics or industrial process control, or simulations used to certify structural integrity of a designed product?"
  },
  {
    "id": 35,
    "pillar": "EU AI Act Compliance",
    "indicator": "High-Risk Practices (Mandatory Compliance)",
    "scoring": "Yes/No",
    "question": "Is the AI system integrated as a safety component into a physical product, such as an industrial robot or machine, a vehicle control system, or a lift/elevator that is already subject to mandatory third-party safety certification under specific EU product law?"
  },
  {
    "id": 36,
    "pillar": "EU AI Act Compliance",
    "indicator": "High-Risk Practices (Mandatory Compliance)",
    "scoring": "Yes/No",
    "question": "Does the system make independent decisions in law enforcement, border control, or migration processes? Or does it serve as a decision-support tool, providing data-driven insights to human professionals who retain full authority and responsibility for final judgments? By integrating human expertise, ethical guidelines, and legal frameworks, do we ensure that decisions are transparent, accountable, and aligned with fundamental rights and societal values?"
  },
  {
    "id": 37,
    "pillar": "EU AI Act Compliance",
    "indicator": "High-Risk Practices (Mandatory Compliance)",
    "scoring": "Yes/No",
    "question": "Is the AI system used for real-time risk assessment or allocation of urgent interventions, such as predicting the critical failure of factory machinery, or prioritizing cybersecurity incident response in a tech service, or determining emergency infrastructure resource allocation in a smart city solution?"
  },
  {
    "id": 38,
    "pillar": "EU AI Act Compliance",
    "indicator": "High-Risk Practices (Mandatory Compliance)",
    "scoring": "Yes/No",
    "question": "Does the AI system have the potential to cause significant injury, death, or severe property damage if it fails or operates incorrectly, such as robotics control systems on a factory floor, an automated vehicle component, or faulty structural design analysis software?"
  },
  {
    "id": 39,
    "pillar": "EU AI Act Compliance",
    "indicator": "Minimal/Low-Risk Practices (Transparency Obligations)",
    "scoring": "Yes/No",
    "question": "Are users of your software or product always informed when they are interacting with an AI (e.g., a chatbot or design assistant)?"
  },
  {
    "id": 40,
    "pillar": "EU AI Act Compliance",
    "indicator": "Minimal/Low-Risk Practices (Transparency Obligations)",
    "scoring": "Yes/No",
    "question": "When your system generates synthetic media (deepfakes, altered images/audio), is the artificial origin clearly labeled and disclosed to the recipient?"
  },
  {
    "id": 41,
    "pillar": "EU AI Act Compliance",
    "indicator": "Minimal/Low-Risk Practices (Transparency Obligations)",
    "scoring": "Yes/No",
    "question": "When the system generates or manipulates text for public release (e.g., product descriptions, reports), is it clearly identified that the content is machine-generated?"
  },
  {
    "id": 42,
    "pillar": "EU AI Act Compliance",
    "indicator": "Minimal/Low-Risk Practices (Transparency Obligations)",
    "scoring": "Yes/No",
    "question": "If your system directly interacts with people (e.g., an automated customer service tool), is it evident to the person that the output is from an AI?"
  },
  {
    "id": 43,
    "pillar": "EU AI Act Compliance",
    "indicator": "Minimal/Low-Risk Practices (Transparency Obligations)",
    "scoring": "Yes/No",
    "question": "Has the AI been reviewed to ensure its recommendations or personalized content do not negatively influence a user's autonomy or well-being (e.g., manipulative advertising)?"
  }
];

export const PILLARS = [
  "Strategy & Value",
  "Governance, Ethics & Compliance",
  "Data Foundations",
  "People, Skills & Culture",
  "Data, Platforms & MLOps",
  "Process & Stakeholders",
  "EU AI Act Compliance",
];